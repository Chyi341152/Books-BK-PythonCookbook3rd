{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1. Reading and Writing CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA -0.18\n",
      "AIG -0.15\n",
      "AXP -0.46\n",
      "{'Price': '39.48', 'Time': '9:36am', 'Volume': '181800', 'Symbol': 'AA', 'Date': '6/11/2007', 'Change': '-0.18'}\n",
      "{'Price': '71.38', 'Time': '9:36am', 'Volume': '195500', 'Symbol': 'AIG', 'Date': '6/11/2007', 'Change': '-0.15'}\n",
      "{'Price': '62.58', 'Time': '9:36am', 'Volume': '935000', 'Symbol': 'AXP', 'Date': '6/11/2007', 'Change': '-0.46'}\n",
      "['Symbol,Price,Date,Time,Change,Volume']\n",
      "['AA,39.48,6/11/2007,9:36am,-0.18,181800']\n",
      "['AIG,71.38,6/11/2007,9:36am,-0.15,195500']\n",
      "['AXP,62.58,6/11/2007,9:36am,-0.46,935000']\n",
      "('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800)\n",
      "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500)\n",
      "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
      "Reading as dicts with type conversion\n",
      "{'Price': 39.48, 'Time': '9:36am', 'Volume': 181800, 'Symbol': 'AA', 'Date': '6/11/2007', 'Change': -0.18}\n",
      "{'Price': 71.38, 'Time': '9:36am', 'Volume': 195500, 'Symbol': 'AIG', 'Date': '6/11/2007', 'Change': -0.15}\n",
      "{'Price': 62.58, 'Time': '9:36am', 'Volume': 935000, 'Symbol': 'AXP', 'Date': '6/11/2007', 'Change': -0.46}\n"
     ]
    }
   ],
   "source": [
    "# getting data in and out of a program \n",
    "\n",
    "import csv\n",
    "\n",
    "# read the data as a sequence of tuples\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv: # row will be a tuple \n",
    "        # Processing row \n",
    "        print(row[0], row[4])\n",
    "\n",
    "from collections import namedtuple\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "\n",
    "# read the data as a sequence of dictionaries\n",
    "import csv \n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "\n",
    "# write CSV data \n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n",
    "       ]\n",
    "with open('stocks.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)\n",
    "\n",
    "# If you have the data as a sequence of dictionaries \n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "{'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "{'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)\n",
    "\n",
    "# Example of reading tab-separated values\n",
    "with open('stocks.csv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        print(row)\n",
    "\n",
    "# extra type conversions on CSV\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items \n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        print(row)\n",
    "\n",
    "print('Reading as dicts with type conversion')\n",
    "field_types = [('Price', float),\n",
    "              ('Change', float),\n",
    "              ('Volume', int)]\n",
    "\n",
    "with open ('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)\n",
    "        \n",
    "# Pandas package. Pandas includes a convenient pandas.read_csv() function that will load CSV data into a DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. Reading and Writing JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"price\": 542.23, \"name\": \"ACME\", \"shares\": 100}\n",
      "{'price': 542.23, 'name': 'ACME', 'shares': 100}\n",
      "{'price': 542.23, 'name': 'ACME', 'shares': 100}\n",
      "false\n",
      "true\n",
      "null\n",
      "{'base': 'stations',\n",
      " 'clouds': {'all': 90},\n",
      " 'cod': 200,\n",
      " 'coord': {'lat': 51.51, 'lon': -0.13},\n",
      " 'dt': 1485789600,\n",
      " 'id': 2643743,\n",
      " 'main': {'humidity': 81,\n",
      "          'pressure': 1012,\n",
      "          'temp': 280.32,\n",
      "          'temp_max': 281.15,\n",
      "          'temp_min': 279.15},\n",
      " 'name': 'London',\n",
      " 'sys': {'country': 'GB',\n",
      "         'id': 5091,\n",
      "         'message': 0.0103,\n",
      "         'sunrise': 1485762037,\n",
      "         'sunset': 1485794875,\n",
      "         'type': 1},\n",
      " 'visibility': 10000,\n",
      " 'weather': [{'description': 'light intensity drizzle',\n",
      "              'icon': '09d',\n",
      "              'id': 300,\n",
      "              'main': 'Drizzle'}],\n",
      " 'wind': {'deg': 80, 'speed': 4.1}}\n",
      "{\"x\": 2, \"__classname__\": \"Point\", \"y\": 3}\n",
      "<__main__.Point object at 0x7f1260a726a0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON (JavaScript Object Notation)\n",
    "import json \n",
    "\n",
    "data = {\n",
    "    'name': 'ACME',\n",
    "    'shares': 100,\n",
    "    'price': 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)\n",
    "print(json_str)\n",
    "# JSON-encoded string back into a Python data structure \n",
    "data = json.loads(json_str)\n",
    "print(data)\n",
    "\n",
    "# With files  Writing JSON data \n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Reading data back \n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print(data)\n",
    "    \n",
    "# JSON encoding supports the basic types of None, bool, int, float, str. lists, tuples, dictionaries \n",
    "# For instance, True is mapped to true, False is mapped to false, and None is mapped to null\n",
    "\n",
    "print(json.dumps(False))\n",
    "print(json.dumps(True))\n",
    "print(json.dumps(None))\n",
    "\n",
    "d = {'a': True, 'b': 'Hello', 'c': None}\n",
    "json.dumps(d)\n",
    "\n",
    "# pprint() function in the pprint module. \n",
    "from urllib.request import urlopen\n",
    "import json \n",
    "u = urlopen('http://samples.openweathermap.org/data/2.5/weather?q=London,uk&appid=b6907d289e10d714a6e88b30761fae22')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "from pprint import pprint\n",
    "pprint(resp)\n",
    "\n",
    "# decode JSON data \n",
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict \n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "\n",
    "# turn JSON dictionary into a Python object \n",
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__=d\n",
    "        \n",
    "data = json.loads(s, object_hook=JSONObject)\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x \n",
    "        self.y = y \n",
    "\n",
    "def serialize_instance(obj):\n",
    "    d = {'__classname__': type(obj).__name__}\n",
    "    d.update(vars(obj))\n",
    "    return d \n",
    "        \n",
    "p = Point(2,3)\n",
    "# serialize instances \n",
    "json.dumps(serialize_instance(p))\n",
    "\n",
    "# Dictionary mapping names to known classes \n",
    "classes = {\n",
    "    'Point': Point \n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Make instance without calling __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "            return obj \n",
    "    else:\n",
    "        return d \n",
    "p = Point(2,3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "print(s)\n",
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "print(a)\n",
    "a.x \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3. Parsing Simple XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk Python to Me: #148 Python Book Authors'  Panel Discussion\n",
      "Sun, 28 Jan 2018 08:00:00 +0000\n",
      "https://talkpython.fm/episodes/show/148/python-book-authors-panel-discussion\n",
      "\n",
      "Evennia: Kicking into gear from a distance\n",
      "Sat, 27 Jan 2018 23:27:46 +0000\n",
      "http://evennia.blogspot.com/2018/01/kicking-into-gear-from-distance.html\n",
      "\n",
      "Weekly Python StackOverflow Report: (cx) stackoverflow python report\n",
      "Sat, 27 Jan 2018 21:56:00 +0000\n",
      "http://python-weekly.blogspot.com/2018/01/cx-stackoverflow-python-report.html\n",
      "\n",
      "Anarcat: A summary of my 2017 work\n",
      "Sat, 27 Jan 2018 16:54:02 +0000\n",
      "https://anarc.at/blog/2018-01-27-summary-2017-work/\n",
      "\n",
      "Sandipan Dey: Image Colorization Using Optimization in Python\n",
      "Sat, 27 Jan 2018 01:09:09 +0000\n",
      "\n",
      "\n",
      "Matthew Rocklin: Write Dumb Code\n",
      "Sat, 27 Jan 2018 00:00:00 +0000\n",
      "https://matthewrocklin.com/blog//work/2018/01/27/write-dumb-code\n",
      "\n",
      "Sumana Harihareswara - Cogito, Ergo Sumana: Preserving Threading In Google Group or Mailman Mailing List Replies with Thunderbird\n",
      "Fri, 26 Jan 2018 22:28:50 +0000\n",
      "https://www.harihareswara.net/sumana/2018/01/26/0\n",
      "\n",
      "PyCon: ¡Presentamos el track de PyCon Charlas!\n",
      "Fri, 26 Jan 2018 17:18:58 +0000\n",
      "http://pycon.blogspot.com/2018/01/presentamos-el-track-de-pycon-charlas.html\n",
      "\n",
      "Yasoob Khalid: DocRaptor review\n",
      "Fri, 26 Jan 2018 16:55:45 +0000\n",
      "https://pythontips.com/2018/01/25/docraptor-review/\n",
      "\n",
      "Python Bytes: #62 Wooey and Gooey are simple Python GUIs\n",
      "Fri, 26 Jan 2018 08:00:00 +0000\n",
      "https://pythonbytes.fm/episodes/show/62/wooey-and-gooey-are-simple-python-guis\n",
      "\n",
      "Amit Saha: Data in CPython\n",
      "Fri, 26 Jan 2018 06:00:00 +0000\n",
      "http://echorand.me/data-in-cpython.html\n",
      "\n",
      "Yasoob Khalid: How I got into programming\n",
      "Fri, 26 Jan 2018 01:57:00 +0000\n",
      "https://pythontips.com/2017/12/01/how-i-got-into-programming/\n",
      "\n",
      "Data School: 9 new pandas updates that will save you time\n",
      "Thu, 25 Jan 2018 17:30:00 +0000\n",
      "http://www.dataschool.io/python-pandas-updates/\n",
      "\n",
      "A. Jesse Jiryu Davis: Embed Interns In Your Team, Don't Assign Them Science Fair Projects\n",
      "Thu, 25 Jan 2018 13:49:32 +0000\n",
      "https://emptysqua.re/blog/embed-interns-in-teams/\n",
      "\n",
      "Dataquest: Introduction to Functional Programming in Python\n",
      "Thu, 25 Jan 2018 09:00:00 +0000\n",
      "https://www.dataquest.io/blog/introduction-functional-programming-python/\n",
      "\n",
      "Real Python: Simplifying Offline Python Deployments With Docker\n",
      "Wed, 24 Jan 2018 14:08:48 +0000\n",
      "https://realpython.com/blog/python/offline-python-deployments-with-docker/\n",
      "\n",
      "PyCharm: PyCharm 2018.1 EAP 2\n",
      "Wed, 24 Jan 2018 12:14:04 +0000\n",
      "http://feedproxy.google.com/~r/Pycharm/~3/PRf-mLNmHMw/\n",
      "\n",
      "Amit Saha: Your options for monitoring multi-process Python applications with Prometheus\n",
      "Wed, 24 Jan 2018 04:00:00 +0000\n",
      "http://echorand.me/your-options-for-monitoring-multi-process-python-applications-with-prometheus.html\n",
      "\n",
      "Ned Batchelder: Python’s misleading readability\n",
      "Wed, 24 Jan 2018 03:17:12 +0000\n",
      "https://nedbatchelder.com//blog/201801/pythons_misleading_readability.html\n",
      "\n",
      "Weekly Python Chat: Duck Typing in Python\n",
      "Tue, 23 Jan 2018 21:30:00 +0000\n",
      "https://www.crowdcast.io/e/duck-typing-2\n",
      "\n",
      "Codementor: How to run and schedule Python scripts on iOS\n",
      "Tue, 23 Jan 2018 18:49:11 +0000\n",
      "https://www.codementor.io/gergelykovcs/how-to-run-and-schedule-python-scripts-on-ios-fqfxvyp7x\n",
      "\n",
      "Mike Driscoll: How to Use wxPython Demo Code Outside the Demo\n",
      "Tue, 23 Jan 2018 18:15:53 +0000\n",
      "http://www.blog.pythonlibrary.org/2018/01/23/how-to-use-wxpython-demo-code-outside-the-demo/\n",
      "\n",
      "Zato Blog: PyCharm and Visual Studio Code integration for Zato API services\n",
      "Tue, 23 Jan 2018 17:40:15 +0000\n",
      "https://zato.io/blog/posts/ide-hot-deployment.html\n",
      "\n",
      "Stack Abuse: Enhancing Python with Custom C Extensions\n",
      "Tue, 23 Jan 2018 15:00:00 +0000\n",
      "http://stackabuse.com/enhancing-python-with-custom-c-extensions/\n",
      "\n",
      "Real Python: Practical Introduction to Web Scraping in Python\n",
      "Tue, 23 Jan 2018 14:09:42 +0000\n",
      "https://realpython.com/blog/python/python-web-scraping-practical-introduction/\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# xml.etree.ElementTree module can be used to extract data from simple XML documents\n",
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed and parse it \n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc= parse(u) # parse the entire XML document into a document object \n",
    "\n",
    "# Extract and output tags of interest \n",
    "for item in doc.iterfind('channel/item'): # find(), iterfind(),and findtext() to search for sepcific XML elements\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "    \n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()\n",
    "# text, and get() method can be used to extract attributes\n",
    "e = doc.find('channel/title')\n",
    "print(e.get('some_attribute'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4. Parsing Huge XML Files Incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60617 13\n",
      "60626 8\n",
      "60651 7\n",
      "60623 6\n",
      "60647 6\n",
      "60625 4\n",
      "60636 4\n",
      "60609 4\n",
      "60613 4\n",
      "60628 4\n",
      "60641 3\n",
      "60622 3\n",
      "60657 3\n",
      "60619 3\n",
      "60629 3\n",
      "60654 2\n",
      "60656 2\n",
      "60644 2\n",
      "60618 2\n",
      "60649 2\n",
      "60638 2\n",
      "60660 1\n",
      "60614 1\n",
      "60631 1\n",
      "60634 1\n",
      "60707 1\n",
      "60630 1\n",
      "60643 1\n",
      "60652 1\n",
      "60637 1\n",
      "60616 1\n",
      "60612 1\n",
      "60639 1\n",
      "60632 1\n",
      "60617 13\n",
      "60626 8\n",
      "60651 7\n",
      "60623 6\n",
      "60647 6\n",
      "60625 4\n",
      "60636 4\n",
      "60609 4\n",
      "60613 4\n",
      "60628 4\n",
      "60641 3\n",
      "60622 3\n",
      "60657 3\n",
      "60619 3\n",
      "60629 3\n",
      "60654 2\n",
      "60656 2\n",
      "60644 2\n",
      "60618 2\n",
      "60649 2\n",
      "60638 2\n",
      "60660 1\n",
      "60614 1\n",
      "60631 1\n",
      "60634 1\n",
      "60707 1\n",
      "60630 1\n",
      "60643 1\n",
      "60652 1\n",
      "60637 1\n",
      "60616 1\n",
      "60612 1\n",
      "60639 1\n",
      "60632 1\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import iterparse \n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # Skip the root element \n",
    "    next(doc)\n",
    "    \n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem \n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass \n",
    "\n",
    "# ranks ZIP codes by the number of pothole reports \n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter \n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "\n",
    "# This version of code runs with a memory footprint of only 7MB\n",
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
