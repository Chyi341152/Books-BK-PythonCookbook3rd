{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1. Reading and Writing CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA -0.18\n",
      "AIG -0.15\n",
      "AXP -0.46\n",
      "{'Price': '39.48', 'Time': '9:36am', 'Volume': '181800', 'Symbol': 'AA', 'Date': '6/11/2007', 'Change': '-0.18'}\n",
      "{'Price': '71.38', 'Time': '9:36am', 'Volume': '195500', 'Symbol': 'AIG', 'Date': '6/11/2007', 'Change': '-0.15'}\n",
      "{'Price': '62.58', 'Time': '9:36am', 'Volume': '935000', 'Symbol': 'AXP', 'Date': '6/11/2007', 'Change': '-0.46'}\n",
      "['Symbol,Price,Date,Time,Change,Volume']\n",
      "['AA,39.48,6/11/2007,9:36am,-0.18,181800']\n",
      "['AIG,71.38,6/11/2007,9:36am,-0.15,195500']\n",
      "['AXP,62.58,6/11/2007,9:36am,-0.46,935000']\n",
      "('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800)\n",
      "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500)\n",
      "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
      "Reading as dicts with type conversion\n",
      "{'Price': 39.48, 'Time': '9:36am', 'Volume': 181800, 'Symbol': 'AA', 'Date': '6/11/2007', 'Change': -0.18}\n",
      "{'Price': 71.38, 'Time': '9:36am', 'Volume': 195500, 'Symbol': 'AIG', 'Date': '6/11/2007', 'Change': -0.15}\n",
      "{'Price': 62.58, 'Time': '9:36am', 'Volume': 935000, 'Symbol': 'AXP', 'Date': '6/11/2007', 'Change': -0.46}\n"
     ]
    }
   ],
   "source": [
    "# getting data in and out of a program \n",
    "\n",
    "import csv\n",
    "\n",
    "# read the data as a sequence of tuples\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv: # row will be a tuple \n",
    "        # Processing row \n",
    "        print(row[0], row[4])\n",
    "\n",
    "from collections import namedtuple\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "\n",
    "# read the data as a sequence of dictionaries\n",
    "import csv \n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "\n",
    "# write CSV data \n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n",
    "       ]\n",
    "with open('stocks.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)\n",
    "\n",
    "# If you have the data as a sequence of dictionaries \n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "{'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "{'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)\n",
    "\n",
    "# Example of reading tab-separated values\n",
    "with open('stocks.csv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        print(row)\n",
    "\n",
    "# extra type conversions on CSV\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items \n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        print(row)\n",
    "\n",
    "print('Reading as dicts with type conversion')\n",
    "field_types = [('Price', float),\n",
    "              ('Change', float),\n",
    "              ('Volume', int)]\n",
    "\n",
    "with open ('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)\n",
    "        \n",
    "# Pandas package. Pandas includes a convenient pandas.read_csv() function that will load CSV data into a DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. Reading and Writing JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"price\": 542.23, \"name\": \"ACME\", \"shares\": 100}\n",
      "{'price': 542.23, 'name': 'ACME', 'shares': 100}\n",
      "{'price': 542.23, 'name': 'ACME', 'shares': 100}\n",
      "false\n",
      "true\n",
      "null\n",
      "{'base': 'stations',\n",
      " 'clouds': {'all': 90},\n",
      " 'cod': 200,\n",
      " 'coord': {'lat': 51.51, 'lon': -0.13},\n",
      " 'dt': 1485789600,\n",
      " 'id': 2643743,\n",
      " 'main': {'humidity': 81,\n",
      "          'pressure': 1012,\n",
      "          'temp': 280.32,\n",
      "          'temp_max': 281.15,\n",
      "          'temp_min': 279.15},\n",
      " 'name': 'London',\n",
      " 'sys': {'country': 'GB',\n",
      "         'id': 5091,\n",
      "         'message': 0.0103,\n",
      "         'sunrise': 1485762037,\n",
      "         'sunset': 1485794875,\n",
      "         'type': 1},\n",
      " 'visibility': 10000,\n",
      " 'weather': [{'description': 'light intensity drizzle',\n",
      "              'icon': '09d',\n",
      "              'id': 300,\n",
      "              'main': 'Drizzle'}],\n",
      " 'wind': {'deg': 80, 'speed': 4.1}}\n",
      "{\"x\": 2, \"__classname__\": \"Point\", \"y\": 3}\n",
      "<__main__.Point object at 0x7f1260a726a0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON (JavaScript Object Notation)\n",
    "import json \n",
    "\n",
    "data = {\n",
    "    'name': 'ACME',\n",
    "    'shares': 100,\n",
    "    'price': 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)\n",
    "print(json_str)\n",
    "# JSON-encoded string back into a Python data structure \n",
    "data = json.loads(json_str)\n",
    "print(data)\n",
    "\n",
    "# With files  Writing JSON data \n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Reading data back \n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print(data)\n",
    "    \n",
    "# JSON encoding supports the basic types of None, bool, int, float, str. lists, tuples, dictionaries \n",
    "# For instance, True is mapped to true, False is mapped to false, and None is mapped to null\n",
    "\n",
    "print(json.dumps(False))\n",
    "print(json.dumps(True))\n",
    "print(json.dumps(None))\n",
    "\n",
    "d = {'a': True, 'b': 'Hello', 'c': None}\n",
    "json.dumps(d)\n",
    "\n",
    "# pprint() function in the pprint module. \n",
    "from urllib.request import urlopen\n",
    "import json \n",
    "u = urlopen('http://samples.openweathermap.org/data/2.5/weather?q=London,uk&appid=b6907d289e10d714a6e88b30761fae22')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "from pprint import pprint\n",
    "pprint(resp)\n",
    "\n",
    "# decode JSON data \n",
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict \n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "\n",
    "# turn JSON dictionary into a Python object \n",
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__=d\n",
    "        \n",
    "data = json.loads(s, object_hook=JSONObject)\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x \n",
    "        self.y = y \n",
    "\n",
    "def serialize_instance(obj):\n",
    "    d = {'__classname__': type(obj).__name__}\n",
    "    d.update(vars(obj))\n",
    "    return d \n",
    "        \n",
    "p = Point(2,3)\n",
    "# serialize instances \n",
    "json.dumps(serialize_instance(p))\n",
    "\n",
    "# Dictionary mapping names to known classes \n",
    "classes = {\n",
    "    'Point': Point \n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Make instance without calling __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "            return obj \n",
    "    else:\n",
    "        return d \n",
    "p = Point(2,3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "print(s)\n",
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "print(a)\n",
    "a.x \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3. Parsing Simple XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk Python to Me: #148 Python Book Authors'  Panel Discussion\n",
      "Sun, 28 Jan 2018 08:00:00 +0000\n",
      "https://talkpython.fm/episodes/show/148/python-book-authors-panel-discussion\n",
      "\n",
      "Evennia: Kicking into gear from a distance\n",
      "Sat, 27 Jan 2018 23:27:46 +0000\n",
      "http://evennia.blogspot.com/2018/01/kicking-into-gear-from-distance.html\n",
      "\n",
      "Weekly Python StackOverflow Report: (cx) stackoverflow python report\n",
      "Sat, 27 Jan 2018 21:56:00 +0000\n",
      "http://python-weekly.blogspot.com/2018/01/cx-stackoverflow-python-report.html\n",
      "\n",
      "Anarcat: A summary of my 2017 work\n",
      "Sat, 27 Jan 2018 16:54:02 +0000\n",
      "https://anarc.at/blog/2018-01-27-summary-2017-work/\n",
      "\n",
      "Sandipan Dey: Image Colorization Using Optimization in Python\n",
      "Sat, 27 Jan 2018 01:09:09 +0000\n",
      "\n",
      "\n",
      "Matthew Rocklin: Write Dumb Code\n",
      "Sat, 27 Jan 2018 00:00:00 +0000\n",
      "https://matthewrocklin.com/blog//work/2018/01/27/write-dumb-code\n",
      "\n",
      "Sumana Harihareswara - Cogito, Ergo Sumana: Preserving Threading In Google Group or Mailman Mailing List Replies with Thunderbird\n",
      "Fri, 26 Jan 2018 22:28:50 +0000\n",
      "https://www.harihareswara.net/sumana/2018/01/26/0\n",
      "\n",
      "PyCon: ¡Presentamos el track de PyCon Charlas!\n",
      "Fri, 26 Jan 2018 17:18:58 +0000\n",
      "http://pycon.blogspot.com/2018/01/presentamos-el-track-de-pycon-charlas.html\n",
      "\n",
      "Yasoob Khalid: DocRaptor review\n",
      "Fri, 26 Jan 2018 16:55:45 +0000\n",
      "https://pythontips.com/2018/01/25/docraptor-review/\n",
      "\n",
      "Python Bytes: #62 Wooey and Gooey are simple Python GUIs\n",
      "Fri, 26 Jan 2018 08:00:00 +0000\n",
      "https://pythonbytes.fm/episodes/show/62/wooey-and-gooey-are-simple-python-guis\n",
      "\n",
      "Amit Saha: Data in CPython\n",
      "Fri, 26 Jan 2018 06:00:00 +0000\n",
      "http://echorand.me/data-in-cpython.html\n",
      "\n",
      "Yasoob Khalid: How I got into programming\n",
      "Fri, 26 Jan 2018 01:57:00 +0000\n",
      "https://pythontips.com/2017/12/01/how-i-got-into-programming/\n",
      "\n",
      "Data School: 9 new pandas updates that will save you time\n",
      "Thu, 25 Jan 2018 17:30:00 +0000\n",
      "http://www.dataschool.io/python-pandas-updates/\n",
      "\n",
      "A. Jesse Jiryu Davis: Embed Interns In Your Team, Don't Assign Them Science Fair Projects\n",
      "Thu, 25 Jan 2018 13:49:32 +0000\n",
      "https://emptysqua.re/blog/embed-interns-in-teams/\n",
      "\n",
      "Dataquest: Introduction to Functional Programming in Python\n",
      "Thu, 25 Jan 2018 09:00:00 +0000\n",
      "https://www.dataquest.io/blog/introduction-functional-programming-python/\n",
      "\n",
      "Real Python: Simplifying Offline Python Deployments With Docker\n",
      "Wed, 24 Jan 2018 14:08:48 +0000\n",
      "https://realpython.com/blog/python/offline-python-deployments-with-docker/\n",
      "\n",
      "PyCharm: PyCharm 2018.1 EAP 2\n",
      "Wed, 24 Jan 2018 12:14:04 +0000\n",
      "http://feedproxy.google.com/~r/Pycharm/~3/PRf-mLNmHMw/\n",
      "\n",
      "Amit Saha: Your options for monitoring multi-process Python applications with Prometheus\n",
      "Wed, 24 Jan 2018 04:00:00 +0000\n",
      "http://echorand.me/your-options-for-monitoring-multi-process-python-applications-with-prometheus.html\n",
      "\n",
      "Ned Batchelder: Python’s misleading readability\n",
      "Wed, 24 Jan 2018 03:17:12 +0000\n",
      "https://nedbatchelder.com//blog/201801/pythons_misleading_readability.html\n",
      "\n",
      "Weekly Python Chat: Duck Typing in Python\n",
      "Tue, 23 Jan 2018 21:30:00 +0000\n",
      "https://www.crowdcast.io/e/duck-typing-2\n",
      "\n",
      "Codementor: How to run and schedule Python scripts on iOS\n",
      "Tue, 23 Jan 2018 18:49:11 +0000\n",
      "https://www.codementor.io/gergelykovcs/how-to-run-and-schedule-python-scripts-on-ios-fqfxvyp7x\n",
      "\n",
      "Mike Driscoll: How to Use wxPython Demo Code Outside the Demo\n",
      "Tue, 23 Jan 2018 18:15:53 +0000\n",
      "http://www.blog.pythonlibrary.org/2018/01/23/how-to-use-wxpython-demo-code-outside-the-demo/\n",
      "\n",
      "Zato Blog: PyCharm and Visual Studio Code integration for Zato API services\n",
      "Tue, 23 Jan 2018 17:40:15 +0000\n",
      "https://zato.io/blog/posts/ide-hot-deployment.html\n",
      "\n",
      "Stack Abuse: Enhancing Python with Custom C Extensions\n",
      "Tue, 23 Jan 2018 15:00:00 +0000\n",
      "http://stackabuse.com/enhancing-python-with-custom-c-extensions/\n",
      "\n",
      "Real Python: Practical Introduction to Web Scraping in Python\n",
      "Tue, 23 Jan 2018 14:09:42 +0000\n",
      "https://realpython.com/blog/python/python-web-scraping-practical-introduction/\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# xml.etree.ElementTree module can be used to extract data from simple XML documents\n",
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed and parse it \n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc= parse(u) # parse the entire XML document into a document object \n",
    "\n",
    "# Extract and output tags of interest \n",
    "for item in doc.iterfind('channel/item'): # find(), iterfind(),and findtext() to search for sepcific XML elements\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "    \n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()\n",
    "# text, and get() method can be used to extract attributes\n",
    "e = doc.find('channel/title')\n",
    "print(e.get('some_attribute'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4. Parsing Huge XML Files Incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60617 13\n",
      "60626 8\n",
      "60651 7\n",
      "60623 6\n",
      "60647 6\n",
      "60625 4\n",
      "60636 4\n",
      "60609 4\n",
      "60613 4\n",
      "60628 4\n",
      "60641 3\n",
      "60622 3\n",
      "60657 3\n",
      "60619 3\n",
      "60629 3\n",
      "60654 2\n",
      "60656 2\n",
      "60644 2\n",
      "60618 2\n",
      "60649 2\n",
      "60638 2\n",
      "60660 1\n",
      "60614 1\n",
      "60631 1\n",
      "60634 1\n",
      "60707 1\n",
      "60630 1\n",
      "60643 1\n",
      "60652 1\n",
      "60637 1\n",
      "60616 1\n",
      "60612 1\n",
      "60639 1\n",
      "60632 1\n",
      "60617 13\n",
      "60626 8\n",
      "60651 7\n",
      "60623 6\n",
      "60647 6\n",
      "60625 4\n",
      "60636 4\n",
      "60609 4\n",
      "60613 4\n",
      "60628 4\n",
      "60641 3\n",
      "60622 3\n",
      "60657 3\n",
      "60619 3\n",
      "60629 3\n",
      "60654 2\n",
      "60656 2\n",
      "60644 2\n",
      "60618 2\n",
      "60649 2\n",
      "60638 2\n",
      "60660 1\n",
      "60614 1\n",
      "60631 1\n",
      "60634 1\n",
      "60707 1\n",
      "60630 1\n",
      "60643 1\n",
      "60652 1\n",
      "60637 1\n",
      "60616 1\n",
      "60612 1\n",
      "60639 1\n",
      "60632 1\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import iterparse \n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # Skip the root element \n",
    "    next(doc)\n",
    "    \n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem \n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass \n",
    "\n",
    "# ranks ZIP codes by the number of pothole reports \n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter \n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "\n",
    "# This version of code runs with a memory footprint of only 7MB\n",
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5. Turning a Dictionary into XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xml.etree.ElementTree library is commonly used for \n",
    "from xml.etree.ElementTree import Element \n",
    "from xml.etree.ElementTree import tostring \n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    '''\n",
    "    Turn a simple dict of key/value pairs into XML\n",
    "    '''\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem \n",
    "\n",
    "s = {'name': 'GOOG', 'shares': 100, 'price': 490.1}\n",
    "e = dict_to_xml('stock', s)\n",
    "tostring(e)\n",
    "\n",
    "e.set('_id', '1234')\n",
    "tostring(e)\n",
    "\n",
    "def dict_to_xml_str(tag, d):\n",
    "    '''\n",
    "    Turn a simple dict of key/value pairs into XML\n",
    "    '''\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key, val))\n",
    "    parts.append('</{}>'.format(tag))\n",
    "    return ''.join(parts)\n",
    "\n",
    "# escape() and unescape() functions in XML.sax.saxutils\n",
    "from xml.sax.saxutils import escape, unescape\n",
    "escape('<spam>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6. Parsing, Modifying, and Rewriting XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "remove() argument must be xml.etree.ElementTree.Element, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7160081667f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Remove a few elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sri'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: remove() argument must be xml.etree.ElementTree.Element, not None"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element \n",
    "doc = parse('potholes.xml')\n",
    "root = doc.getroot()\n",
    "\n",
    "# Remove a few elements \n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))\n",
    "\n",
    "# Insert a new element after <nm>...</nm>\n",
    "root.getchildren().index(root.find('nm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.7. Parsing XML Documents with Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some queries that work \n",
    "doc.findtext('author')\n",
    "doc.find('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.8. Interacting with a Relational Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table portfolio already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8ac995a9254f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Once you have a cursor, you can start executing SQL queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'create table portfolio (symbol text, shares integer, price real)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table portfolio already exists"
     ]
    }
   ],
   "source": [
    "# select, insert, delete rows in a relational database\n",
    "stocks = [\n",
    "    ('GOOG', 100, 490.1),\n",
    "    ('AAPL', 50, 545.75),\n",
    "    ('FB', 150, 7.45),\n",
    "    ('HPQ', 75, 33.2),\n",
    "]\n",
    "import sqlite3\n",
    "db = sqlite3.connect('database.db')\n",
    "\n",
    "# Once you have a cursor, you can start executing SQL queries\n",
    "c = db.cursor()\n",
    "c.execute('create table portfolio (symbol text, shares integer, price real)')\n",
    "db.commit() \n",
    "\n",
    "# insert a sequence of rows into the data \n",
    "c.executemany('insert into portfolic values (?,?,?)', stocks)\n",
    "db.commit()\n",
    "\n",
    "# insert a sequence of rows into the data \n",
    "c.executemany('insert into portfolio values(?,?,?)', stocks)\n",
    "db.commit\n",
    "\n",
    "# perform a query \n",
    "for row in db.execute('select * from portfolio'):\n",
    "    print(row)\n",
    "\n",
    "min_price = 100 \n",
    "for row in db.execute('select * from portfolio where price >= ?', (min_price,)):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.9. Decoding and Encoding Hexadecimal Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656C6C6F'\n",
      "68656C6C6F\n"
     ]
    }
   ],
   "source": [
    "# Initial byte string \n",
    "s = b'hello'\n",
    "\n",
    "# Encode as hex \n",
    "import binascii\n",
    "h = binascii.b2a_hex(s)\n",
    "\n",
    "# Decode back to bytes\n",
    "binascii.a2b_hex(h)\n",
    "\n",
    "# base64.b16decode() and base64.b16encode() functions only operate with uppercase \n",
    "\n",
    "import base64\n",
    "h = base64.b16encode(s)\n",
    "base64.b16decode(h)\n",
    "\n",
    "h = base64.b16encode(s)\n",
    "print(h)\n",
    "print(h.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.10. Decoding and Encoding Base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'aGVsbG8='\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode or encode binary data using Base64 encoding \n",
    "\n",
    "# Some byte data \n",
    "s = b'hello'\n",
    "import base64\n",
    "\n",
    "# Encode as Base64\n",
    "a = base64.b64encode(s)\n",
    "print(a)\n",
    "\n",
    "# Decode from Base64 \n",
    "base64.b64decode(a) # decoding Base64 both byte strings and Unicode text strings can be supplied "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.11. Reading and Writing Binary Arrays of Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.3, 4.5)\n",
      "(6, 7.8, 9.0)\n",
      "(12, 13.4, 56.7)\n"
     ]
    }
   ],
   "source": [
    "from struct import Struct\n",
    "\n",
    "def write_records(records, format, f):\n",
    "    '''\n",
    "    Write a sequence of tuples to a binary file of structures.\n",
    "    '''\n",
    "    record_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(record_struct.pack(*r))\n",
    "\n",
    "\n",
    "\n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)\n",
    "\n",
    "# Example\n",
    "if __name__ == '__main__':\n",
    "    records = [(1, 2.3, 4.5),\n",
    "              (6, 7.8, 9.0),\n",
    "              (12, 13.4, 56.7)]\n",
    "    with open('data.b', 'wb') as f:\n",
    "        write_records(records, '<idd', f)\n",
    "    \n",
    "    with open('data.b','rb') as f:\n",
    "              for rec in read_records('<idd', f):\n",
    "                  print(rec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.12. Reading Nested and Variable-SIzed Binary Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
